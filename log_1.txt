Data type: (13840, 28, 28, 3)
Shape: (13840,)
<keras.engine.functional.Functional object at 0x7f69d55dc6d0>
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 1)]          0           []                               
                                                                                                  
 embedding (Embedding)          (None, 1, 100)       300         ['input_2[0][0]']                
                                                                                                  
 input_1 (InputLayer)           [(None, 100)]        0           []                               
                                                                                                  
 flatten (Flatten)              (None, 100)          0           ['embedding[0][0]']              
                                                                                                  
 concatenate (Concatenate)      (None, 200)          0           ['input_1[0][0]',                
                                                                  'flatten[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 1024)         205824      ['concatenate[0][0]']            
                                                                                                  
 batch_normalization (BatchNorm  (None, 1024)        4096        ['dense[0][0]']                  
 alization)                                                                                       
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 1024)         0           ['batch_normalization[0][0]']    
                                                                                                  
 dense_1 (Dense)                (None, 100352)       102860800   ['leaky_re_lu[0][0]']            
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 100352)      401408      ['dense_1[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 100352)       0           ['batch_normalization_1[0][0]']  
                                                                                                  
 reshape (Reshape)              (None, 28, 28, 128)  0           ['leaky_re_lu_1[0][0]']          
                                                                                                  
 conv2d_transpose (Conv2DTransp  (None, 28, 28, 128)  262272     ['reshape[0][0]']                
 ose)                                                                                             
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_transpose[0][0]']       
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  
                                                                                                  
 conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 128)  262272     ['leaky_re_lu_2[0][0]']          
 spose)                                                                                           
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_transpose_1[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu_3 (LeakyReLU)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  
                                                                                                  
 conv2d_transpose_2 (Conv2DTran  (None, 28, 28, 128)  262272     ['leaky_re_lu_3[0][0]']          
 spose)                                                                                           
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_transpose_2[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 leaky_re_lu_4 (LeakyReLU)      (None, 28, 28, 128)  0           ['batch_normalization_4[0][0]']  
                                                                                                  
 conv2d (Conv2D)                (None, 28, 28, 3)    3459        ['leaky_re_lu_4[0][0]']          
                                                                                                  
==================================================================================================
Total params: 104,264,239
Trainable params: 104,060,719
Non-trainable params: 203,520
__________________________________________________________________________________________________
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_1 (Conv2D)           (None, 14, 14, 64)        1792      
                                                                 
 leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 64)        0         
                                                                 
 dropout (Dropout)           (None, 14, 14, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     
                                                                 
 batch_normalization_5 (Batc  (None, 7, 7, 128)        512       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_6 (LeakyReLU)   (None, 7, 7, 128)         0         
                                                                 
 dropout_1 (Dropout)         (None, 7, 7, 128)         0         
                                                                 
 conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    
                                                                 
 batch_normalization_6 (Batc  (None, 4, 4, 256)        1024      
 hNormalization)                                                 
                                                                 
 leaky_re_lu_7 (LeakyReLU)   (None, 4, 4, 256)         0         
                                                                 
 dropout_2 (Dropout)         (None, 4, 4, 256)         0         
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 1)                 4097      
                                                                 
=================================================================
Total params: 376,449
Trainable params: 375,681
Non-trainable params: 768
_________________________________________________________________
32
(32, 100)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 536ms/step
32
(32, 100)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 405ms/step
32
(32, 100)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 385ms/step
32
(32, 100)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 376ms/step
32
(32, 100)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 386ms/step
(32, 100) (32,)
Epoch 1, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.7987925410270691
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 582ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 396ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 382ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 2, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.3754730224609375
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 381ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 381ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 427ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 3, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.21032610535621643
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 408ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 384ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 382ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 4, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.16231054067611694
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 380ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 418ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 379ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 5, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.10575896501541138
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 400ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 396ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 409ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 6, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.03312583267688751
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 397ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 390ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 402ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 7, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.02968778647482395
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 382ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 435ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 393ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 8, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.011398900300264359
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 404ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 391ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 386ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 9, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.01282479427754879
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 405ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 391ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 379ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 10, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.013118424452841282
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 397ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 393ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 408ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 11, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.011170141398906708
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 399ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 445ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 390ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 12, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.015175349079072475
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 422ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 381ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 379ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 13, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.006964709609746933
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 382ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 429ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 374ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 14, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.010664941743016243
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 410ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 384ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 387ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 15, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.013440342620015144
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 396ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 368ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 358ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 16, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.00537674967199564
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 362ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 381ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 366ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 17, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.011604185216128826
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 417ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 374ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 357ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 18, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.006300828419625759
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 378ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 414ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 363ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 19, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.006933905184268951
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 403ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 371ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 354ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 20, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.006770210340619087
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 378ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 397ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 373ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 21, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.003831252921372652
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 397ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 363ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 370ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 22, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.00417392747476697
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 360ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 400ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 363ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 23, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.005675486288964748
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 382ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 372ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 402ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 24, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.004297928418964148
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 374ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 450ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 372ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 25, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.0031286280136555433
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 397ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 367ms/step
(32, 28, 28, 3)
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 387ms/step
(32, 28, 28, 3)
(32, 100) (32,)
Epoch 26, Discriminator Loss: ([0.32133424282073975, 0.875], [0.29260173439979553, 0.96875]), GAN Loss: 0.002614460652694106
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 360ms/step
(32, 28, 28, 3)
